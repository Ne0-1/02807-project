{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "717bf5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import mmh3\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f991438",
   "metadata": {},
   "source": [
    "We start by defining the necessary functions to get document similarity (week 5 of course exercises). Please note that the listhash, minhash, and signatures are gone. We will not be using them in this model as we saw a decrease in model performance. We did not perform any extensive analysis and we believe this is due to the information loss as we minhash. And as we won't minhash there is no need to create hashes at all and therefore, there won't be any signatures. Just q-shingles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "3b10c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create shingle function\n",
    "def shingles(string:str,q:int):\n",
    "    output = set()\n",
    "    for i in range(len(string)+1):\n",
    "        if i < q:\n",
    "            pass\n",
    "        else:\n",
    "            output.add(''.join(string[i-q:i]))\n",
    "    return output\n",
    "\n",
    "#create jaccard sim function\n",
    "def jaccard(doc1, doc2):\n",
    "    intersect = np.intersect1d(doc1,doc2)\n",
    "    union = np.union1d(doc1,doc2)\n",
    "    if len(union) != 0:\n",
    "        return len(intersect) / len(union)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "#create document sim function\n",
    "def similarity(docs:dict):\n",
    "    output = np.zeros((len(docs.keys()),len(docs.keys())))\n",
    "    for key1, value1 in tqdm(docs.items()):\n",
    "        for key2, value2 in docs.items():\n",
    "            if key1 <= key2:\n",
    "                pass\n",
    "            else:\n",
    "                jac_value = jaccard(np.array(value1),np.array(value2))\n",
    "                output[key1,key2] = jac_value\n",
    "    return np.tril(output) + np.triu(output.T, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882e3126",
   "metadata": {},
   "source": [
    "Now we create the \"training\" loop. The training actually happens as we create the document similarity matrix. This function just evaluates one fold of a cross validation ind gives us the predicted labels for the test set in that fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "2b22fbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_knn(x, y_train,test_idx,low,high,k_neighbours=5):\n",
    "    y_test = []\n",
    "    mask = np.ones(len(x),bool)\n",
    "    mask[y_test] = False\n",
    "    for i in test_idx:\n",
    "        ind = []\n",
    "        temp = np.argpartition(x[i], -k_neighbours)[-k_neighbours:]\n",
    "        temp = np.flip(temp)\n",
    "        for idx in temp:\n",
    "            if idx>=high or idx < low:\n",
    "                ind.append(idx)\n",
    "        topk = x[i][ind]\n",
    "        labels = {j: y_train[j] for j in ind}\n",
    "        ham = 0\n",
    "        spam = 0\n",
    "        for key, value in labels.items():\n",
    "            if value == 0:\n",
    "                ham += x[i][key]\n",
    "            if value == 1:\n",
    "                spam += x[i][key]\n",
    "        \n",
    "        if ham>spam:\n",
    "            y_test.append(0)\n",
    "        if ham == spam:\n",
    "            y_test.append(0)\n",
    "        if ham<spam:\n",
    "            y_test.append(1)\n",
    "        \n",
    "\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a59d75",
   "metadata": {},
   "source": [
    "Now we get to a piece of code that we are not really proud of. However, we decided to use no sklearn models in this section (except for evaluating f1-scores and accuracies). We evaluate the model with a $k$ (in KNN) of 5 and a $q$ of 5 as that was suggested by the course. We evaluate through a 5-fold cross validation and save all performance metrics from each run.\n",
    "\n",
    "We also keep the predictions of the outer test set in order to do McNemar tests between models. This will be done in another notebook as this one has become quite extensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21026cd3",
   "metadata": {},
   "source": [
    "### SPAM (SMS)\n",
    "Sorry for variable names, we realised that this was SMS messages and not emails later in the process.\n",
    "\n",
    "##### Q-KNN (on raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b3edd846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "emails = pd.read_csv('clean_data/clean_spam.csv', encoding='latin')\n",
    "emails.tokens = emails.tokens.apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "aad80640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get shingles and similarity\n",
    "q=5\n",
    "email_shingles = {emails.index[_]: shingles(emails.iloc[:,1][_], q=q) for _ in emails.index}\n",
    "email_similarity = similarity(email_shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "7eb97d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "kfold=5\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "test_set_percent = ((len(emails)/kfold)/len(emails))\n",
    "test_size = round(test_set_percent*len(emails))\n",
    "former_test_idx = 0\n",
    "y_tests = []\n",
    "predicted = []\n",
    "for i in range(kfold):\n",
    "    y_test = emails['binary'][former_test_idx:(i+1)*test_size]\n",
    "    y_tests = y_tests + list(y_test)\n",
    "    y_idx = y_test.index\n",
    "    mask = np.ones(len(emails), bool)\n",
    "    mask[y_idx] = False\n",
    "    y_train = emails['binary'][mask]\n",
    "    y_pred = weighted_knn(email_similarity,y_train,y_idx,former_test_idx,(i+1)*test_size,5)\n",
    "    predicted = predicted + list(y_pred)\n",
    "    f1_scores.append(f1_score(y_test,y_pred))\n",
    "    accuracies.append(accuracy_score(y_test,y_pred))\n",
    "    former_test_idx += test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "b4628b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = np.array(f1_scores)\n",
    "accuracies = np.array(accuracies)\n",
    "np.savetxt('q-knn_results/f1_q-knn_raw_spam.txt',f1_scores)\n",
    "np.savetxt('q-knn_results/acc_q-knn_raw_spam.txt', accuracies)\n",
    "np.savetxt('q-knn_results/pred_q-knn_raw_spam.txt',np.array(predicted), fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad86392b",
   "metadata": {},
   "source": [
    "##### Bag of Words-KNN (on tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "c467a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get bag of words as sets for each email\n",
    "email_bow = {emails.index[i]: set(emails['tokens'][i]) for i in range(len(emails))}\n",
    "#get similarity between documents\n",
    "email_bow_sim = similarity(email_bow)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "kfold=5\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "test_set_percent = ((len(emails)/kfold)/len(emails))\n",
    "test_size = round(test_set_percent*len(emails))\n",
    "former_test_idx = 0\n",
    "y_tests = []\n",
    "predicted = []\n",
    "for i in range(kfold):\n",
    "    y_test = emails['binary'][former_test_idx:(i+1)*test_size]\n",
    "    y_tests = y_tests + list(y_test)\n",
    "    y_idx = y_test.index\n",
    "    mask = np.ones(len(emails), bool)\n",
    "    mask[y_idx] = False\n",
    "    y_train = emails['binary'][mask]\n",
    "    y_pred = weighted_knn(email_bow_sim,y_train,y_idx,former_test_idx,(i+1)*test_size,5)\n",
    "    predicted = predicted + list(y_pred)\n",
    "    f1_scores.append(f1_score(y_test,y_pred))\n",
    "    accuracies.append(accuracy_score(y_test,y_pred))\n",
    "    former_test_idx += test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "562a2c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = np.array(f1_scores)\n",
    "accuracies = np.array(accuracies)\n",
    "np.savetxt('q-knn_results/f1_token-knn_spam.txt',f1_scores)\n",
    "np.savetxt('q-knn_results/acc_token-knn_spam.txt', accuracies)\n",
    "np.savetxt('q-knn_results/pred_token-knn_spam.txt',np.array(predicted), fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1b966",
   "metadata": {},
   "source": [
    "##### Q-KNN (on tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "bf54b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get bag of words as sets for each email\n",
    "email_shingles = {emails.index[_]: shingles(emails.iloc[:,3][_], q=q) for _ in emails.index}\n",
    "#get similarity between documents\n",
    "email_similarity = similarity(email_shingles)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "kfold=5\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "test_set_percent = ((len(emails)/kfold)/len(emails))\n",
    "test_size = round(test_set_percent*len(emails))\n",
    "former_test_idx = 0\n",
    "y_tests = []\n",
    "predicted = []\n",
    "for i in range(kfold):\n",
    "    y_test = emails['binary'][former_test_idx:(i+1)*test_size]\n",
    "    y_tests = y_tests + list(y_test)\n",
    "    y_idx = y_test.index\n",
    "    mask = np.ones(len(emails), bool)\n",
    "    mask[y_idx] = False\n",
    "    y_train = emails['binary'][mask]\n",
    "    y_pred = weighted_knn(email_similarity,y_train,y_idx,former_test_idx,(i+1)*test_size,5)\n",
    "    predicted = predicted + list(y_pred)\n",
    "    f1_scores.append(f1_score(y_test,y_pred))\n",
    "    accuracies.append(accuracy_score(y_test,y_pred))\n",
    "    former_test_idx += test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "41f77cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = np.array(f1_scores)\n",
    "accuracies = np.array(accuracies)\n",
    "np.savetxt('q-knn_results/f1_q-knn_spam.txt',f1_scores)\n",
    "np.savetxt('q-knn_results/acc_q-knn_spam.txt', accuracies)\n",
    "np.savetxt('q-knn_results/pred_q-knn_spam.txt',np.array(predicted), fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532579b",
   "metadata": {},
   "source": [
    "##### Bag of Words-KNN (on raw data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "78c25115",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails['token_raw'] = [emails['text'][i].split(' ') for i in emails.index]\n",
    "#get bag of words as sets for each email\n",
    "email_bow = {emails.index[i]: set(emails['token_raw'][i]) for i in range(len(emails))}\n",
    "#get similarity between documents\n",
    "email_bow_sim = similarity(email_bow)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "kfold=5\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "test_set_percent = ((len(emails)/kfold)/len(emails))\n",
    "test_size = round(test_set_percent*len(emails))\n",
    "former_test_idx = 0\n",
    "y_tests = []\n",
    "predicted = []\n",
    "for i in range(kfold):\n",
    "    y_test = emails['binary'][former_test_idx:(i+1)*test_size]\n",
    "    y_tests = y_tests + list(y_test)\n",
    "    y_idx = y_test.index\n",
    "    mask = np.ones(len(emails), bool)\n",
    "    mask[y_idx] = False\n",
    "    y_train = emails['binary'][mask]\n",
    "    y_pred = weighted_knn(email_bow_sim,y_train,y_idx,former_test_idx,(i+1)*test_size,5)\n",
    "    predicted = predicted + list(y_pred)\n",
    "    f1_scores.append(f1_score(y_test,y_pred))\n",
    "    accuracies.append(accuracy_score(y_test,y_pred))\n",
    "    former_test_idx += test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "b496d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = np.array(f1_scores)\n",
    "accuracies = np.array(accuracies)\n",
    "np.savetxt('q-knn_results/f1_token-knn_raw_spam.txt',f1_scores)\n",
    "np.savetxt('q-knn_results/acc_token-knn_raw_spam.txt', accuracies)\n",
    "np.savetxt('q-knn_results/pred_token-knn_raw_spam.txt',np.array(predicted), fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0714dd",
   "metadata": {},
   "source": [
    "### SPAM ASSASSIN (EMAILS)\n",
    "This is actually email data!\n",
    "\n",
    "##### Q-KNN (on raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "edd1c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = pd.read_csv('clean_data/clean_completeSpamAssassin.csv', encoding='latin')\n",
    "emails = emails.sample(frac=1).reset_index(drop=True)\n",
    "np.random.seed(0)\n",
    "emails.to_csv('clean_data/clean_completeSpamAssassin_shuffled.csv', index=False)\n",
    "emails.tokens = emails.tokens.apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "ddb4ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get bag of words as sets for each email\n",
    "email_shingles = {emails.index[_]: shingles(emails.iloc[:,0][_], q=q) for _ in emails.index}\n",
    "#get similarity between documents\n",
    "email_similarity = similarity(email_shingles)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "kfold=5\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "test_set_percent = ((len(emails)/kfold)/len(emails))\n",
    "test_size = round(test_set_percent*len(emails))\n",
    "former_test_idx = 0\n",
    "y_tests = []\n",
    "predicted = []\n",
    "for i in range(kfold):\n",
    "    y_test = emails['binary'][former_test_idx:(i+1)*test_size]\n",
    "    y_tests = y_tests + list(y_test)\n",
    "    y_idx = y_test.index\n",
    "    mask = np.ones(len(emails), bool)\n",
    "    mask[y_idx] = False\n",
    "    y_train = emails['binary'][mask]\n",
    "    y_pred = weighted_knn(email_similarity,y_train,y_idx,former_test_idx,(i+1)*test_size,5)\n",
    "    predicted = predicted + list(y_pred)\n",
    "    f1_scores.append(f1_score(y_test,y_pred))\n",
    "    accuracies.append(accuracy_score(y_test,y_pred))\n",
    "    former_test_idx += test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "10710c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = np.array(f1_scores)\n",
    "accuracies = np.array(accuracies)\n",
    "np.savetxt('q-knn_results/f1_q-knn_raw_assassin.txt',f1_scores)\n",
    "np.savetxt('q-knn_results/acc_q-knn_raw_assasin.txt', accuracies)\n",
    "np.savetxt('q-knn_results/pred_q-knn_raw_assassin.txt',np.array(predicted), fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380913ec",
   "metadata": {},
   "source": [
    "##### Bag of Words-KNN (on tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "b27ee24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get bag of words as sets for each email\n",
    "email_bow = {emails.index[i]: set(emails['tokens'][i]) for i in range(len(emails))}\n",
    "#get similarity between documents\n",
    "email_bow_sim = similarity(email_bow)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "kfold=5\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "test_set_percent = ((len(emails)/kfold)/len(emails))\n",
    "test_size = round(test_set_percent*len(emails))\n",
    "former_test_idx = 0\n",
    "y_tests = []\n",
    "predicted = []\n",
    "for i in range(kfold):\n",
    "    y_test = emails['binary'][former_test_idx:(i+1)*test_size]\n",
    "    y_tests = y_tests + list(y_test)\n",
    "    y_idx = y_test.index\n",
    "    mask = np.ones(len(emails), bool)\n",
    "    mask[y_idx] = False\n",
    "    y_train = emails['binary'][mask]\n",
    "    y_pred = weighted_knn(email_bow_sim,y_train,y_idx,former_test_idx,(i+1)*test_size,5)\n",
    "    predicted = predicted + list(y_pred)\n",
    "    f1_scores.append(f1_score(y_test,y_pred))\n",
    "    accuracies.append(accuracy_score(y_test,y_pred))\n",
    "    former_test_idx += test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "35bf8acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = np.array(f1_scores)\n",
    "accuracies = np.array(accuracies)\n",
    "np.savetxt('q-knn_results/f1_token-knn_assassin.txt',f1_scores)\n",
    "np.savetxt('q-knn_results/acc_token-knn_assassin.txt', accuracies)\n",
    "np.savetxt('q-knn_results/pred_token-knn_assassin.txt',np.array(predicted), fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a17ea73",
   "metadata": {},
   "source": [
    "##### Q-KNN (on tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "ba6f7f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get bag of words as sets for each email\n",
    "email_shingles = {emails.index[_]: shingles(emails.iloc[:,3][_], q=q) for _ in emails.index}\n",
    "#get similarity between documents\n",
    "email_similarity = similarity(email_shingles)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "kfold=5\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "test_set_percent = ((len(emails)/kfold)/len(emails))\n",
    "test_size = round(test_set_percent*len(emails))\n",
    "former_test_idx = 0\n",
    "y_tests = []\n",
    "predicted = []\n",
    "for i in range(kfold):\n",
    "    y_test = emails['binary'][former_test_idx:(i+1)*test_size]\n",
    "    y_tests = y_tests + list(y_test)\n",
    "    y_idx = y_test.index\n",
    "    mask = np.ones(len(emails), bool)\n",
    "    mask[y_idx] = False\n",
    "    y_train = emails['binary'][mask]\n",
    "    y_pred = weighted_knn(email_similarity,y_train,y_idx,former_test_idx,(i+1)*test_size,5)\n",
    "    predicted = predicted + list(y_pred)\n",
    "    f1_scores.append(f1_score(y_test,y_pred))\n",
    "    accuracies.append(accuracy_score(y_test,y_pred))\n",
    "    former_test_idx += test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "19efcf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = np.array(f1_scores)\n",
    "accuracies = np.array(accuracies)\n",
    "np.savetxt('q-knn_results/f1_q-knn_assassin.txt',f1_scores)\n",
    "np.savetxt('q-knn_results/acc_q-knn_assassin.txt', accuracies)\n",
    "np.savetxt('q-knn_results/pred_q-knn_assassin.txt',np.array(predicted), fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26210bb",
   "metadata": {},
   "source": [
    "##### Bag of Words-KNN (on raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "0f396c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails['token_raw'] = [emails['text'][i].split(' ') for i in emails.index]\n",
    "#get bag of words as sets for each email\n",
    "email_bow = {emails.index[i]: set(emails['token_raw'][i]) for i in range(len(emails))}\n",
    "#get similarity between documents\n",
    "email_bow_sim = similarity(email_bow)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "kfold=5\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "test_set_percent = ((len(emails)/kfold)/len(emails))\n",
    "test_size = round(test_set_percent*len(emails))\n",
    "former_test_idx = 0\n",
    "y_tests = []\n",
    "predicted = []\n",
    "for i in range(kfold):\n",
    "    y_test = emails['binary'][former_test_idx:(i+1)*test_size]\n",
    "    y_tests = y_tests + list(y_test)\n",
    "    y_idx = y_test.index\n",
    "    mask = np.ones(len(emails), bool)\n",
    "    mask[y_idx] = False\n",
    "    y_train = emails['binary'][mask]\n",
    "    y_pred = weighted_knn(email_bow_sim,y_train,y_idx,former_test_idx,(i+1)*test_size,5)\n",
    "    predicted = predicted + list(y_pred)\n",
    "    f1_scores.append(f1_score(y_test,y_pred))\n",
    "    accuracies.append(accuracy_score(y_test,y_pred))\n",
    "    former_test_idx += test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "abb9c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = np.array(f1_scores)\n",
    "accuracies = np.array(accuracies)\n",
    "np.savetxt('q-knn_results/f1_token-knn_raw_assassin.txt',f1_scores)\n",
    "np.savetxt('q-knn_results/acc_token-knn_raw_assassin.txt', accuracies)\n",
    "np.savetxt('q-knn_results/pred_token-knn_raw_assassin.txt',np.array(predicted), fmt=\"%s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
