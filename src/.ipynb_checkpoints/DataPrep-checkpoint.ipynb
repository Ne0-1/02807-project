{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d87c1d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54f625c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "#tqdm_pandas(tqdm())\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib as mpl\n",
    "\n",
    "def setup_mpl():\n",
    "    mpl.rcParams['font.family'] = 'Times New Roman'\n",
    "    return\n",
    "setup_mpl()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4358f4af",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95206e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "\n",
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()\n",
    "\n",
    "# Keep numbers / Remove numbers / Substitute numbers with token\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    #Common english stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Substituting urls with \n",
    "    url_regex = r'(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})'\n",
    "    text = re.sub(r'http\\S+', '#URL#', str(text)) # Maybe change to single-character-symbol -> shingles\n",
    "    #Tokenize using nltk\n",
    "    word_tokens = word_tokenize(text.lower())\n",
    "    #removing none letter characters and stop words\n",
    "    filtered_sentence = [w for w in word_tokens if w not in stop_words and w.isalpha()]\n",
    "    #Conduct stemming\n",
    "    processed_text = [porter.stem(t) for t in filtered_sentence]\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57c0765",
   "metadata": {},
   "source": [
    "### SMS spam: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65709702",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/regular/spam.csv\"\n",
    "SMS = pd.read_csv(PATH)[['v1','v2']]\n",
    "SMS = SMS.rename(columns={'v1': 'label', 'v2': 'text'})\n",
    "\n",
    "label = SMS['label'].values\n",
    "text = SMS['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3608ae50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5572/5572 [00:02<00:00, 2104.88it/s]\n",
      "100%|██████████| 5572/5572 [00:00<00:00, 1374502.26it/s]\n",
      "100%|██████████| 5551/5551 [00:00<00:00, 2184516.94it/s]\n"
     ]
    }
   ],
   "source": [
    "SMS['tokens'] = [preprocess(x) for x in tqdm(SMS['text'])]\n",
    "SMS['str_tokens'] = [' '.join(x) for x in tqdm(SMS['tokens'])]\n",
    "# Removing rows of emtpty tokens\n",
    "SMS = SMS[SMS['tokens'].astype(bool)]\n",
    "binary_dict = {'ham': 0, 'spam': 1}\n",
    "SMS['binary'] = [binary_dict[x] for x in tqdm(SMS['label'])]\n",
    "SMS.to_csv('../data/clean/clean_spam.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de36270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce33546a",
   "metadata": {},
   "source": [
    "### Email spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db8e9add",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/regular/completeSpamAssassin.csv\"\n",
    "EMAIL = pd.read_csv(PATH, index_col = 'Unnamed: 0')\n",
    "\n",
    "EMAIL.rename(columns = {'Label':'label', 'Body':'text'}, inplace = True)\n",
    "\n",
    "EMAIL['label'] = EMAIL['label'].replace(0, 'ham')\n",
    "EMAIL['label'] = EMAIL['label'].replace(1, 'spam')\n",
    "\n",
    "# Removing 'empty' rows\n",
    "EMAIL.text = np.where(EMAIL.text.isin(['empty']), np.nan, EMAIL.text)\n",
    "EMAIL = EMAIL.dropna().reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d6a368a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5512/5512 [00:28<00:00, 196.27it/s]\n",
      "100%|██████████| 5512/5512 [00:00<00:00, 198809.87it/s]\n",
      "100%|██████████| 5507/5507 [00:00<00:00, 1789158.18it/s]\n"
     ]
    }
   ],
   "source": [
    "EMAIL['tokens'] = [preprocess(x) for x in tqdm(EMAIL['text'])]\n",
    "EMAIL['str_tokens'] = [' '.join(x) for x in tqdm(EMAIL['tokens'])]\n",
    "EMAIL = EMAIL[EMAIL['tokens'].astype(bool)]\n",
    "binary_dict = {'ham': 0, 'spam': 1}\n",
    "EMAIL['binary'] = [binary_dict[x] for x in tqdm(EMAIL['label'])]\n",
    "EMAIL.to_csv('../data/clean/clean_completeSpamAssassin.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dba8089c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>str_tokens</th>\n",
       "      <th>binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nSave up to 70% on Life Insurance.\\nWhy Spend...</td>\n",
       "      <td>spam</td>\n",
       "      <td>[save, life, insur, spend, life, quot, save, e...</td>\n",
       "      <td>save life insur spend life quot save ensur fam...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1) Fight The Risk of Cancer!\\nhttp://www.adcli...</td>\n",
       "      <td>spam</td>\n",
       "      <td>[fight, risk, cancer, url, slim, guarante, los...</td>\n",
       "      <td>fight risk cancer url slim guarante lose lb da...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1) Fight The Risk of Cancer!\\nhttp://www.adcli...</td>\n",
       "      <td>spam</td>\n",
       "      <td>[fight, risk, cancer, url, slim, guarante, los...</td>\n",
       "      <td>fight risk cancer url slim guarante lose lb da...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>##############################################...</td>\n",
       "      <td>spam</td>\n",
       "      <td>[adult, club, offer, free, membership, instant...</td>\n",
       "      <td>adult club offer free membership instant acces...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I thought you might like these:\\n1) Slim Down ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>[thought, might, like, slim, guarante, lose, l...</td>\n",
       "      <td>thought might like slim guarante lose lb day u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5507</th>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>ham</td>\n",
       "      <td>[isilo, tm, palm, os, pocket, pc, window, ente...</td>\n",
       "      <td>isilo tm palm os pocket pc window enter isilo ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5508</th>\n",
       "      <td>EFFector       Vol. 15, No. 35       November ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>[effector, vol, novemb, ren, public, electron,...</td>\n",
       "      <td>effector vol novemb ren public electron fronti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5509</th>\n",
       "      <td>\\nWe have extended our Free seat sale until Th...</td>\n",
       "      <td>ham</td>\n",
       "      <td>[extend, free, seat, sale, thursday, novemb, d...</td>\n",
       "      <td>extend free seat sale thursday novemb detail s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5510</th>\n",
       "      <td>___           ___           ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>[insignific, matter, heavili, overemphasis, hu...</td>\n",
       "      <td>insignific matter heavili overemphasis hugh mt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5511</th>\n",
       "      <td>IN THIS ISSUE:01. Readers write\\n02. Extension...</td>\n",
       "      <td>ham</td>\n",
       "      <td>[reader, write, extens, search, dumb, messag, ...</td>\n",
       "      <td>reader write extens search dumb messag revisit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5507 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text label  \\\n",
       "0     \\nSave up to 70% on Life Insurance.\\nWhy Spend...  spam   \n",
       "1     1) Fight The Risk of Cancer!\\nhttp://www.adcli...  spam   \n",
       "2     1) Fight The Risk of Cancer!\\nhttp://www.adcli...  spam   \n",
       "3     ##############################################...  spam   \n",
       "4     I thought you might like these:\\n1) Slim Down ...  spam   \n",
       "...                                                 ...   ...   \n",
       "5507  ----------------------------------------------...   ham   \n",
       "5508  EFFector       Vol. 15, No. 35       November ...   ham   \n",
       "5509  \\nWe have extended our Free seat sale until Th...   ham   \n",
       "5510                    ___           ___           ...   ham   \n",
       "5511  IN THIS ISSUE:01. Readers write\\n02. Extension...   ham   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [save, life, insur, spend, life, quot, save, e...   \n",
       "1     [fight, risk, cancer, url, slim, guarante, los...   \n",
       "2     [fight, risk, cancer, url, slim, guarante, los...   \n",
       "3     [adult, club, offer, free, membership, instant...   \n",
       "4     [thought, might, like, slim, guarante, lose, l...   \n",
       "...                                                 ...   \n",
       "5507  [isilo, tm, palm, os, pocket, pc, window, ente...   \n",
       "5508  [effector, vol, novemb, ren, public, electron,...   \n",
       "5509  [extend, free, seat, sale, thursday, novemb, d...   \n",
       "5510  [insignific, matter, heavili, overemphasis, hu...   \n",
       "5511  [reader, write, extens, search, dumb, messag, ...   \n",
       "\n",
       "                                             str_tokens  binary  \n",
       "0     save life insur spend life quot save ensur fam...       1  \n",
       "1     fight risk cancer url slim guarante lose lb da...       1  \n",
       "2     fight risk cancer url slim guarante lose lb da...       1  \n",
       "3     adult club offer free membership instant acces...       1  \n",
       "4     thought might like slim guarante lose lb day u...       1  \n",
       "...                                                 ...     ...  \n",
       "5507  isilo tm palm os pocket pc window enter isilo ...       0  \n",
       "5508  effector vol novemb ren public electron fronti...       0  \n",
       "5509  extend free seat sale thursday novemb detail s...       0  \n",
       "5510  insignific matter heavili overemphasis hugh mt...       0  \n",
       "5511  reader write extens search dumb messag revisit...       0  \n",
       "\n",
       "[5507 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMAIL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d97d878",
   "metadata": {},
   "source": [
    "## Job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67e7a4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fraudulent</td>\n",
       "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fraudulent</td>\n",
       "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fraudulent</td>\n",
       "      <td>Valor Services provides Workforce Solutions th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fraudulent</td>\n",
       "      <td>Our passion for improving quality of life thro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fraudulent</td>\n",
       "      <td>SpotSource Solutions LLC is a Global Human Cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17872</th>\n",
       "      <td>fraudulent</td>\n",
       "      <td>Flite delivers ad innovation at scale to the w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17875</th>\n",
       "      <td>fraudulent</td>\n",
       "      <td>Vend is looking for some awesome new talent to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17876</th>\n",
       "      <td>fraudulent</td>\n",
       "      <td>WebLinc is the e-commerce platform and service...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17877</th>\n",
       "      <td>fraudulent</td>\n",
       "      <td>We Provide Full Time Permanent Positions for m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17879</th>\n",
       "      <td>fraudulent</td>\n",
       "      <td>Vend is looking for some awesome new talent to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            label                                               text\n",
       "0      fraudulent  We're Food52, and we've created a groundbreaki...\n",
       "1      fraudulent  90 Seconds, the worlds Cloud Video Production ...\n",
       "2      fraudulent  Valor Services provides Workforce Solutions th...\n",
       "3      fraudulent  Our passion for improving quality of life thro...\n",
       "4      fraudulent  SpotSource Solutions LLC is a Global Human Cap...\n",
       "...           ...                                                ...\n",
       "17872  fraudulent  Flite delivers ad innovation at scale to the w...\n",
       "17875  fraudulent  Vend is looking for some awesome new talent to...\n",
       "17876  fraudulent  WebLinc is the e-commerce platform and service...\n",
       "17877  fraudulent  We Provide Full Time Permanent Positions for m...\n",
       "17879  fraudulent  Vend is looking for some awesome new talent to...\n",
       "\n",
       "[14572 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"../data/regular/Job_postings.csv\"\n",
    "JOB = pd.read_csv(PATH, usecols=['company_profile', 'description', 'fraudulent'])\n",
    "\n",
    "JOB[\"text\"] = JOB[\"company_profile\"] + \" \" + JOB[\"description\"]\n",
    "\n",
    "JOB.rename(columns = {'fraudulent':'label'}, inplace = True)\n",
    "\n",
    "JOB['label'] = JOB['label'].replace(0, 'fraudulent')\n",
    "JOB['label'] = JOB['label'].replace(1, 'genuine')\n",
    "\n",
    "JOB = JOB.drop(columns=['company_profile', 'description'])\n",
    "JOB = JOB.dropna()\n",
    "\n",
    "JOB\n",
    "# Removing 'empty' rows\n",
    "#EMAIL.Body = np.where(EMAIL.Body.isin(['empty']), np.nan, EMAIL.Body)\n",
    "#EMAIL = EMAIL.dropna().reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630a87cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 9777/14572 [01:00<00:35, 136.09it/s]"
     ]
    }
   ],
   "source": [
    "JOB['tokens'] = [preprocess(x) for x in tqdm(JOB['text'])]\n",
    "JOB['str_tokens'] = [' '.join(x) for x in tqdm(JOB['tokens'])]\n",
    "JOB = JOB[JOB['tokens'].astype(bool)]\n",
    "binary_dict = {'genuine': 0, 'fraudulent': 1}\n",
    "JOB['binary'] = [binary_dict[x] for x in tqdm(JOB['label'])]\n",
    "JOB.to_csv('../data/clean/clean_Job_postings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e07cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c6ddca",
   "metadata": {},
   "source": [
    "## NEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/regular/NEWS.csv\"\n",
    "NEWS = pd.read_csv(PATH, usecols=['text', 'label'])\n",
    "\n",
    "NEWS['tokens'] = [preprocess(x) for x in tqdm(NEWS['text'])]\n",
    "NEWS['str_tokens'] = [' '.join(x) for x in tqdm(NEWS['tokens'])]\n",
    "NEWS = NEWS[NEWS['tokens'].astype(bool)]\n",
    "binary_dict = {'real': 0, 'fake': 1}\n",
    "NEWS['binary'] = [binary_dict[x] for x in tqdm(NEWS['label'])]\n",
    "NEWS.to_csv('../data/clean/clean_News.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b78193e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
